{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Aco2YIyGwnlo"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, utils\n",
    "from torch. utils.data import DataLoader\n",
    "from torchvision.transforms import Resize, Grayscale, ToTensor, Compose, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7v44tDVZwnlz",
    "outputId": "6351f279-3853-42fb-a450-dbcfe52789df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f69712bd510>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For reproducibility\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.abenchmark = False\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "gTR8quM0wnl8",
    "outputId": "04166b3b-3cef-434c-c376-c847274bc9e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../data/train_32x32.mat\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "test_batch_size = 100\n",
    "\n",
    "# Transformations\n",
    "# Mnist to size 32, svhn to grayscale\n",
    "# Normalize all datasets\n",
    "mnist_transformations = Compose([\n",
    "    Resize(32),\n",
    "    ToTensor(),\n",
    "    Normalize((0.5,), (0.5,))\n",
    "])\n",
    "svhn_transformations = Compose([\n",
    "    Grayscale(num_output_channels=1),\n",
    "    ToTensor(),\n",
    "    Normalize((0.5,), (0.5,))\n",
    "])\n",
    "# Data Source\n",
    "svhn_train = datasets.SVHN('../data', split='train', download=True,\n",
    "                           transform=svhn_transformations)\n",
    "svhn_test = datasets.SVHN('../data', split='test', download=True,\n",
    "                          transform=svhn_transformations)\n",
    "mnist_train = datasets.MNIST('../data', train=True, download=True,\n",
    "                             transform=mnist_transformations)\n",
    "mnist_test = datasets.MNIST('../data', train=False, download=True,\n",
    "                            transform=mnist_transformations)\n",
    "\n",
    "# Data loaders\n",
    "svhn_train_loader = DataLoader(svhn_train,\n",
    "                               batch_size=batch_size, shuffle=True)\n",
    "svhn_test_loader = DataLoader(svhn_test,\n",
    "                              batch_size=test_batch_size, shuffle=True)\n",
    "mnist_test_loader = DataLoader(mnist_test,\n",
    "                               batch_size=test_batch_size, shuffle=True)\n",
    "mnist_train_loader = DataLoader(mnist_train,\n",
    "                                batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XRt6VxNkwnmD"
   },
   "outputs": [],
   "source": [
    "# Try to use cuda\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nE6hYrcbwnmJ"
   },
   "outputs": [],
   "source": [
    "# Definition of Encoder network\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.seq1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(stride=2, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(32, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(stride=2, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.seq2 = nn.Sequential(\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq1(x)\n",
    "        x = x.view(x.size(0), 4096)\n",
    "        x = F.dropout(self.seq2(x), training=self.training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WvNnMqYzwnmV"
   },
   "outputs": [],
   "source": [
    "# Definition of classifier network\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K8t2cWqawnmZ"
   },
   "outputs": [],
   "source": [
    "# Send models to cuda\n",
    "cls1_model = Classifier().to(device)\n",
    "cls2_model = Classifier().to(device)\n",
    "enc_model = Encoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pUOS_XqDwnmf"
   },
   "outputs": [],
   "source": [
    "# Method for xavier initialization\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "ClEJW_NLwnmk",
    "outputId": "1baca7bc-d46c-4fdc-ffca-4f4473c283d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (seq): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Classifier(\n",
      "  (seq): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Encoder(\n",
      "  (seq1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "  )\n",
      "  (seq2): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "    (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Apply xavier initialization\n",
    "print(cls1_model.apply(init_weights))\n",
    "print(cls2_model.apply(init_weights))\n",
    "print(enc_model.apply(init_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init tensorboard writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init tensorboard writer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "tb = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    images_mnist, labels = next(iter(mnist_train_loader))\n",
    "    images_mnist = images_mnist.to(device)\n",
    "    temp = enc_model(images_mnist)\n",
    "    \n",
    "    # Send mnist images to tensorboard\n",
    "    grid = utils.make_grid(images_mnist)\n",
    "    tb.add_image(\"original images mnist\", grid)\n",
    "    \n",
    "    # Send graphs of the model to tensorboard\n",
    "    tb.add_graph(enc_model, images_mnist)\n",
    "    tb.add_graph(cls1_model, temp)\n",
    "    del temp\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "with torch.no_grad():\n",
    "    images_svhn, labels = next(iter(svhn_train_loader))\n",
    "    images_svhn = images_svhn.to(device)\n",
    "    \n",
    "    # Send svhn images to tensorboard\n",
    "    grid = utils.make_grid(images_svhn)\n",
    "    tb.add_image(\"original images svhn\", grid)\n",
    "    # Send graphs of the model to tensorboard\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def get_images_and_encoding(n, loader):\n",
    "    # Get n batches of images from loader and return their encoded version\n",
    "    with torch.no_grad(): # So that our cuda memory will be flushed after usage\n",
    "        images, labels = next(iter(loader))\n",
    "        images = images.to(device)\n",
    "        temp = enc_model(images)\n",
    "        enc = temp.to('cpu')\n",
    "        del temp\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        for i in range(n - 1):\n",
    "            imgs, l = next(iter(loader))\n",
    "            with torch.no_grad():\n",
    "                imgs = imgs.to(device)\n",
    "                labels = torch.cat((labels, l), 0)\n",
    "                temp = enc_model(imgs)\n",
    "                enc = torch.cat((enc, temp.to('cpu')), 0)\n",
    "                del temp\n",
    "                torch.cuda.empty_cache()\n",
    "        return enc, labels\n",
    "\n",
    "\n",
    "def snapshot_latent_space(flavour_text):\n",
    "    # Get latent space images from mnist and svhn, send them to tensorboard for view later\n",
    "    enc, labels = get_images_and_encoding(10, mnist_train_loader)\n",
    "    enc2, labels2 = get_images_and_encoding(10, svhn_train_loader)\n",
    "    enc = torch.cat((enc, enc2), 0)\n",
    "    labels = torch.cat((labels, labels2), 0)\n",
    "    tb.add_embedding(enc,\n",
    "                     metadata=labels + 10 * torch.cat((torch.zeros(enc.shape[0] // 2), torch.ones(enc.shape[0] // 2)),0),\n",
    "                     tag=flavour_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make snapshot of latent space\n",
    "snapshot_latent_space(\"Latent Space without training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wJTPR2ttwnmp"
   },
   "outputs": [],
   "source": [
    "# Create optimizers and learning rate schedulers\n",
    "opt_enc = optim.Adam(enc_model.parameters(),\n",
    "                     lr=0.0002, weight_decay=0.0005)\n",
    "opt_cls1 = optim.Adam(cls1_model.parameters(),\n",
    "                      lr=0.0002, weight_decay=0.0005)\n",
    "opt_cls2 = optim.Adam(cls2_model.parameters(),\n",
    "                      lr=0.0002, weight_decay=0.0005)\n",
    "enc_scheduler = optim.lr_scheduler.MultiStepLR(opt_enc, milestones=[10, 20, 30, 40], gamma=0.1)\n",
    "cls1_scheduler = optim.lr_scheduler.MultiStepLR(opt_cls1, milestones=[10, 20, 30, 40], gamma=0.1)\n",
    "cls2_scheduler = optim.lr_scheduler.MultiStepLR(opt_cls2, milestones=[10, 20, 30, 40], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Niidsu3swnmv"
   },
   "outputs": [],
   "source": [
    "# Discrepancy function\n",
    "def discrepancy(out1, out2):\n",
    "    # We use softmax here as classifiers doesn't perform it, as we use their output in various losses\n",
    "    return torch.mean(torch.abs(F.softmax(out1, dim=1) - F.softmax(out2, dim=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r6XAojhqwnm0"
   },
   "outputs": [],
   "source": [
    "# Function to test the performance of the network\n",
    "def test(test_loader):\n",
    "    enc_model.eval()\n",
    "    cls1_model.eval()\n",
    "    cls2_model.eval()\n",
    "    correct_amount = 0\n",
    "    size = 0\n",
    "\n",
    "    # Iterate through test loader\n",
    "    for batch_idx, (data, labels) in enumerate(test_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        feat = enc_model(data)\n",
    "        output1 = cls1_model(feat)\n",
    "        output2 = cls2_model(feat)\n",
    "        # Get ensemble of the output\n",
    "        output_ensemble = output1 + output2\n",
    "        pred_ensemble = output_ensemble.data.max(1)[1]\n",
    "        k = labels.data.size()[0]\n",
    "        correct_amount += pred_ensemble.eq(labels.data).cpu().sum()\n",
    "        size += k\n",
    "    return 100. * correct_amount / size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mXn9f8rp5Vdz"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "source_only_epochs = 2 # Number of epochs to train the classifiers for source domain\n",
    "n_epochs = 50\n",
    "num_k = 4  # Number of time we repeat last step\n",
    "cross_entropy_loss = nn.CrossEntropyLoss().to(device)\n",
    "svhn_train_res = []\n",
    "svhn_test_res = []\n",
    "mnist_test_res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after source only learning\n",
      "SVHN Train Accuracy 93.14331817626953\n",
      "SVHN Test Accuracy 89.92394256591797\n",
      "MNIST Test Accuracy 62.4900016784668\n"
     ]
    }
   ],
   "source": [
    "# Train the network on source only before performing domain adaptation\n",
    "for epoch in range(source_only_epochs):\n",
    "    cls1_model.train()\n",
    "    cls2_model.train()\n",
    "    enc_model.train()\n",
    "\n",
    "    for idx, (x_s, y_s) in enumerate(svhn_train_loader):\n",
    "        x_s, y_s = x_s.to(device), y_s.to(device)\n",
    "        opt_cls1.zero_grad()\n",
    "        opt_cls2.zero_grad()\n",
    "        opt_enc.zero_grad()\n",
    "\n",
    "        # STEP 1 of the training - simply learn on source data\n",
    "        feat_s = enc_model(x_s)\n",
    "        out_s1 = cls1_model(feat_s)\n",
    "        out_s2 = cls2_model(feat_s)\n",
    "\n",
    "        loss_s1 = cross_entropy_loss(out_s1, y_s)\n",
    "        loss_s2 = cross_entropy_loss(out_s2, y_s)\n",
    "        loss_s = loss_s1 + loss_s2\n",
    "        loss_s.backward()\n",
    "        opt_enc.step()\n",
    "        opt_cls1.step()\n",
    "        opt_cls2.step()\n",
    "acc1 = test(svhn_train_loader)\n",
    "acc2 = test(svhn_test_loader)\n",
    "acc3 = test(mnist_test_loader)\n",
    "print(f\"Accuracy after source only learning\")\n",
    "print(\"SVHN Train Accuracy\", acc1.item())\n",
    "print(\"SVHN Test Accuracy\", acc2.item())\n",
    "print(\"MNIST Test Accuracy\", acc3.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0LsTsJ9ywnm3",
    "outputId": "30c2fbf2-d02c-4cbe-ff7c-9e11fb92791f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 0\n",
      "\n",
      "SVHN Train Accuracy 58.5732421875\n",
      "SVHN Test Accuracy 58.48571014404297\n",
      "MNIST Test Accuracy 81.76000213623047\n",
      "\n",
      "\n",
      "Epoch 1\n",
      "\n",
      "SVHN Train Accuracy 69.25208282470703\n",
      "SVHN Test Accuracy 69.6412124633789\n",
      "MNIST Test Accuracy 82.06999969482422\n",
      "\n",
      "\n",
      "Epoch 2\n",
      "\n",
      "SVHN Train Accuracy 62.930503845214844\n",
      "SVHN Test Accuracy 62.27335739135742\n",
      "MNIST Test Accuracy 87.19999694824219\n",
      "\n",
      "\n",
      "Epoch 3\n",
      "\n",
      "SVHN Train Accuracy 74.95802307128906\n",
      "SVHN Test Accuracy 73.77842712402344\n",
      "MNIST Test Accuracy 90.48999786376953\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "\n",
      "SVHN Train Accuracy 81.39154052734375\n",
      "SVHN Test Accuracy 79.64044189453125\n",
      "MNIST Test Accuracy 93.0199966430664\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "\n",
      "SVHN Train Accuracy 83.137451171875\n",
      "SVHN Test Accuracy 81.5842056274414\n",
      "MNIST Test Accuracy 94.1500015258789\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "\n",
      "SVHN Train Accuracy 75.00579833984375\n",
      "SVHN Test Accuracy 73.93976593017578\n",
      "MNIST Test Accuracy 95.27999877929688\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "\n",
      "SVHN Train Accuracy 83.92645263671875\n",
      "SVHN Test Accuracy 82.6329116821289\n",
      "MNIST Test Accuracy 95.12000274658203\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "\n",
      "SVHN Train Accuracy 83.87594604492188\n",
      "SVHN Test Accuracy 82.44852447509766\n",
      "MNIST Test Accuracy 95.19999694824219\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "\n",
      "SVHN Train Accuracy 86.00133514404297\n",
      "SVHN Test Accuracy 83.68546295166016\n",
      "MNIST Test Accuracy 95.45999908447266\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "\n",
      "SVHN Train Accuracy 89.13005065917969\n",
      "SVHN Test Accuracy 87.20420837402344\n",
      "MNIST Test Accuracy 97.0999984741211\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "\n",
      "SVHN Train Accuracy 89.31023406982422\n",
      "SVHN Test Accuracy 87.05055236816406\n",
      "MNIST Test Accuracy 97.45999908447266\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "\n",
      "SVHN Train Accuracy 88.54307556152344\n",
      "SVHN Test Accuracy 86.8546371459961\n",
      "MNIST Test Accuracy 97.61000061035156\n",
      "\n",
      "\n",
      "Epoch 13\n",
      "\n",
      "SVHN Train Accuracy 86.99783325195312\n",
      "SVHN Test Accuracy 85.07990264892578\n",
      "MNIST Test Accuracy 97.62000274658203\n",
      "\n",
      "\n",
      "Epoch 14\n",
      "\n",
      "SVHN Train Accuracy 90.28215789794922\n",
      "SVHN Test Accuracy 87.54994201660156\n",
      "MNIST Test Accuracy 97.83999633789062\n",
      "\n",
      "\n",
      "Epoch 15\n",
      "\n",
      "SVHN Train Accuracy 90.24803161621094\n",
      "SVHN Test Accuracy 88.14920043945312\n",
      "MNIST Test Accuracy 97.95999908447266\n",
      "\n",
      "\n",
      "Epoch 16\n",
      "\n",
      "SVHN Train Accuracy 88.53624725341797\n",
      "SVHN Test Accuracy 85.98263549804688\n",
      "MNIST Test Accuracy 97.77999877929688\n",
      "\n",
      "\n",
      "Epoch 17\n",
      "\n",
      "SVHN Train Accuracy 89.21468353271484\n",
      "SVHN Test Accuracy 86.63951873779297\n",
      "MNIST Test Accuracy 98.06999969482422\n",
      "\n",
      "\n",
      "Epoch 18\n",
      "\n",
      "SVHN Train Accuracy 91.26363372802734\n",
      "SVHN Test Accuracy 88.1568832397461\n",
      "MNIST Test Accuracy 98.05000305175781\n",
      "\n",
      "\n",
      "Epoch 19\n",
      "\n",
      "SVHN Train Accuracy 89.48086547851562\n",
      "SVHN Test Accuracy 86.47049713134766\n",
      "MNIST Test Accuracy 98.19999694824219\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "\n",
      "SVHN Train Accuracy 88.78878784179688\n",
      "SVHN Test Accuracy 86.17086791992188\n",
      "MNIST Test Accuracy 98.22000122070312\n",
      "\n",
      "\n",
      "Epoch 21\n",
      "\n",
      "SVHN Train Accuracy 88.91163635253906\n",
      "SVHN Test Accuracy 86.0978775024414\n",
      "MNIST Test Accuracy 98.29000091552734\n",
      "\n",
      "\n",
      "Epoch 22\n",
      "\n",
      "SVHN Train Accuracy 89.20922088623047\n",
      "SVHN Test Accuracy 86.76244354248047\n",
      "MNIST Test Accuracy 98.19000244140625\n",
      "\n",
      "\n",
      "Epoch 23\n",
      "\n",
      "SVHN Train Accuracy 89.10002136230469\n",
      "SVHN Test Accuracy 86.38214874267578\n",
      "MNIST Test Accuracy 98.3499984741211\n",
      "\n",
      "\n",
      "Epoch 24\n",
      "\n",
      "SVHN Train Accuracy 89.14916229248047\n",
      "SVHN Test Accuracy 86.71250915527344\n",
      "MNIST Test Accuracy 98.30000305175781\n",
      "\n",
      "\n",
      "Epoch 25\n",
      "\n",
      "SVHN Train Accuracy 89.6269302368164\n",
      "SVHN Test Accuracy 86.68946075439453\n",
      "MNIST Test Accuracy 98.33000183105469\n",
      "\n",
      "\n",
      "Epoch 26\n",
      "\n",
      "SVHN Train Accuracy 89.55867767333984\n",
      "SVHN Test Accuracy 87.04671478271484\n",
      "MNIST Test Accuracy 98.33999633789062\n",
      "\n",
      "\n",
      "Epoch 27\n",
      "\n",
      "SVHN Train Accuracy 88.1540298461914\n",
      "SVHN Test Accuracy 85.52935028076172\n",
      "MNIST Test Accuracy 98.41000366210938\n",
      "\n",
      "\n",
      "Epoch 28\n",
      "\n",
      "SVHN Train Accuracy 89.53410339355469\n",
      "SVHN Test Accuracy 86.83543395996094\n",
      "MNIST Test Accuracy 98.36000061035156\n",
      "\n",
      "\n",
      "Epoch 29\n",
      "\n",
      "SVHN Train Accuracy 88.33422088623047\n",
      "SVHN Test Accuracy 85.8059310913086\n",
      "MNIST Test Accuracy 98.37999725341797\n",
      "\n",
      "\n",
      "Epoch 30\n",
      "\n",
      "SVHN Train Accuracy 88.39019012451172\n",
      "SVHN Test Accuracy 86.14781951904297\n",
      "MNIST Test Accuracy 98.41000366210938\n",
      "\n",
      "\n",
      "Epoch 31\n",
      "\n",
      "SVHN Train Accuracy 89.03858947753906\n",
      "SVHN Test Accuracy 86.45513153076172\n",
      "MNIST Test Accuracy 98.41999816894531\n",
      "\n",
      "\n",
      "Epoch 32\n",
      "\n",
      "SVHN Train Accuracy 88.768310546875\n",
      "SVHN Test Accuracy 86.31684112548828\n",
      "MNIST Test Accuracy 98.37999725341797\n",
      "\n",
      "\n",
      "Epoch 33\n",
      "\n",
      "SVHN Train Accuracy 89.91632080078125\n",
      "SVHN Test Accuracy 87.09281158447266\n",
      "MNIST Test Accuracy 98.43000030517578\n",
      "\n",
      "\n",
      "Epoch 34\n",
      "\n",
      "SVHN Train Accuracy 88.5799331665039\n",
      "SVHN Test Accuracy 86.18238830566406\n",
      "MNIST Test Accuracy 98.37000274658203\n",
      "\n",
      "\n",
      "Epoch 35\n",
      "\n",
      "SVHN Train Accuracy 89.17509460449219\n",
      "SVHN Test Accuracy 86.27458190917969\n",
      "MNIST Test Accuracy 98.44000244140625\n",
      "\n",
      "\n",
      "Epoch 36\n",
      "\n",
      "SVHN Train Accuracy 89.3443603515625\n",
      "SVHN Test Accuracy 86.74324035644531\n",
      "MNIST Test Accuracy 98.41000366210938\n",
      "\n",
      "\n",
      "Epoch 37\n",
      "\n",
      "SVHN Train Accuracy 89.49861145019531\n",
      "SVHN Test Accuracy 86.7970199584961\n",
      "MNIST Test Accuracy 98.33999633789062\n",
      "\n",
      "\n",
      "Epoch 38\n",
      "\n",
      "SVHN Train Accuracy 88.28507995605469\n",
      "SVHN Test Accuracy 86.05562591552734\n",
      "MNIST Test Accuracy 98.44999694824219\n",
      "\n",
      "\n",
      "Epoch 39\n",
      "\n",
      "SVHN Train Accuracy 88.9717025756836\n",
      "SVHN Test Accuracy 86.37446594238281\n",
      "MNIST Test Accuracy 98.41999816894531\n",
      "\n",
      "\n",
      "Epoch 40\n",
      "\n",
      "SVHN Train Accuracy 89.36347198486328\n",
      "SVHN Test Accuracy 86.68561553955078\n",
      "MNIST Test Accuracy 98.41999816894531\n",
      "\n",
      "\n",
      "Epoch 41\n",
      "\n",
      "SVHN Train Accuracy 89.41807556152344\n",
      "SVHN Test Accuracy 86.84695434570312\n",
      "MNIST Test Accuracy 98.44000244140625\n",
      "\n",
      "\n",
      "Epoch 42\n",
      "\n",
      "SVHN Train Accuracy 88.8119888305664\n",
      "SVHN Test Accuracy 86.20159912109375\n",
      "MNIST Test Accuracy 98.44000244140625\n",
      "\n",
      "\n",
      "Epoch 43\n",
      "\n",
      "SVHN Train Accuracy 89.29112243652344\n",
      "SVHN Test Accuracy 86.74324035644531\n",
      "MNIST Test Accuracy 98.45999908447266\n",
      "\n",
      "\n",
      "Epoch 44\n",
      "\n",
      "SVHN Train Accuracy 88.31510925292969\n",
      "SVHN Test Accuracy 86.03257751464844\n",
      "MNIST Test Accuracy 98.38999938964844\n",
      "\n",
      "\n",
      "Epoch 45\n",
      "\n",
      "SVHN Train Accuracy 89.1136703491211\n",
      "SVHN Test Accuracy 86.60110473632812\n",
      "MNIST Test Accuracy 98.37000274658203\n",
      "\n",
      "\n",
      "Epoch 46\n",
      "\n",
      "SVHN Train Accuracy 89.34163665771484\n",
      "SVHN Test Accuracy 86.72787475585938\n",
      "MNIST Test Accuracy 98.33999633789062\n",
      "\n",
      "\n",
      "Epoch 47\n",
      "\n",
      "SVHN Train Accuracy 88.78059387207031\n",
      "SVHN Test Accuracy 86.04409790039062\n",
      "MNIST Test Accuracy 98.5\n",
      "\n",
      "\n",
      "Epoch 48\n",
      "\n",
      "SVHN Train Accuracy 87.65715026855469\n",
      "SVHN Test Accuracy 85.3948974609375\n",
      "MNIST Test Accuracy 98.33999633789062\n",
      "\n",
      "\n",
      "Epoch 49\n",
      "\n",
      "SVHN Train Accuracy 88.82154846191406\n",
      "SVHN Test Accuracy 86.23233032226562\n",
      "MNIST Test Accuracy 98.4000015258789\n"
     ]
    }
   ],
   "source": [
    "# Training of the model\n",
    "for epoch in range(n_epochs):\n",
    "    cls1_model.train()\n",
    "    cls2_model.train()\n",
    "    enc_model.train()\n",
    "\n",
    "    # Create iterator over mnist (as we will use it inside of the training)\n",
    "    mn = iter(mnist_train_loader)\n",
    "    for idx, (x_s, y_s) in enumerate(svhn_train_loader):\n",
    "\n",
    "        # Try to get images from iterator, if it ended - reload\n",
    "        try:\n",
    "            x_t, _ = mn.next()\n",
    "            x_t = x_t.to(device)\n",
    "        except StopIteration:\n",
    "            mn = iter(mnist_train_loader)\n",
    "            x_t, _ = mn.next()\n",
    "            x_t = x_t.to(device)\n",
    "        x_s, y_s = x_s.to(device), y_s.to(device)\n",
    "        opt_cls1.zero_grad()\n",
    "        opt_cls2.zero_grad()\n",
    "        opt_enc.zero_grad()\n",
    "\n",
    "        # STEP 1 of the training - simply learn on source data\n",
    "        feat_s = enc_model(x_s)\n",
    "        out_s1 = cls1_model(feat_s)\n",
    "        out_s2 = cls2_model(feat_s)\n",
    "\n",
    "        loss_s1 = cross_entropy_loss(out_s1, y_s)\n",
    "        loss_s2 = cross_entropy_loss(out_s2, y_s)\n",
    "        loss_s = loss_s1 + loss_s2\n",
    "        loss_s.backward()\n",
    "        opt_enc.step()\n",
    "        opt_cls1.step()\n",
    "        opt_cls2.step()\n",
    "\n",
    "        opt_cls1.zero_grad()\n",
    "        opt_cls2.zero_grad()\n",
    "        opt_enc.zero_grad()\n",
    "\n",
    "        # STEP 2 of the training - maximize discrepancy\n",
    "        feat_s = enc_model(x_s)\n",
    "        out_s1 = cls1_model(feat_s)\n",
    "        out_s2 = cls2_model(feat_s)\n",
    "\n",
    "        feat_t = enc_model(x_t)\n",
    "        out_t1 = cls1_model(feat_t)\n",
    "        out_t2 = cls2_model(feat_t)\n",
    "\n",
    "        loss_s1 = cross_entropy_loss(out_s1, y_s)\n",
    "        loss_s2 = cross_entropy_loss(out_s2, y_s)\n",
    "        loss_s = loss_s1 + loss_s2\n",
    "        loss_dis = discrepancy(out_t1, out_t2)\n",
    "        loss = loss_s - loss_dis\n",
    "        loss.backward()\n",
    "        opt_cls1.step()\n",
    "        opt_cls2.step()\n",
    "\n",
    "        opt_cls1.zero_grad()\n",
    "        opt_cls2.zero_grad()\n",
    "        opt_enc.zero_grad()\n",
    "\n",
    "        # Step 3 of the training - minimize discrepancy, repeat it num_k times\n",
    "        for i in range(num_k):\n",
    "            feat_t = enc_model(x_t)\n",
    "            out_t1 = cls1_model(feat_t)\n",
    "            out_t2 = cls2_model(feat_t)\n",
    "            loss_dis = discrepancy(out_t1, out_t2)\n",
    "            loss_dis.backward()\n",
    "            opt_enc.step()\n",
    "\n",
    "            opt_cls1.zero_grad()\n",
    "            opt_cls2.zero_grad()\n",
    "            opt_enc.zero_grad()\n",
    "\n",
    "    # Test the network after each epoch and report the results\n",
    "    svhn_train_res.append(test(svhn_train_loader))\n",
    "    svhn_test_res.append(test(svhn_test_loader))\n",
    "    mnist_test_res.append(test(mnist_test_loader))\n",
    "    print(f\"\\n\\nEpoch {epoch}\\n\")\n",
    "    print(\"SVHN Train Accuracy\", svhn_train_res[-1].item())\n",
    "    print(\"SVHN Test Accuracy\", svhn_test_res[-1].item())\n",
    "    print(\"MNIST Test Accuracy\", mnist_test_res[-1].item())\n",
    "    tb.add_scalar(\"SVHN Train Accuracy\", svhn_train_res[-1])\n",
    "    tb.add_scalar(\"SVHN Test Accuracy\", svhn_test_res[-1])\n",
    "    tb.add_scalar(\"MNIST Test Accuracy\", mnist_test_res[-1])\n",
    "\n",
    "    # Save states of the networks\n",
    "    torch.save(enc_model.state_dict(), \"encoder.pt\")\n",
    "    torch.save(cls1_model.state_dict(), \"classifier1.pt\")\n",
    "    torch.save(cls2_model.state_dict(), \"classifier2.pt\")\n",
    "\n",
    "    # Step into the learning rate scheduler\n",
    "    enc_scheduler.step()\n",
    "    cls1_scheduler.step()\n",
    "    cls2_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make snapshot of latent space after training\n",
    "snapshot_latent_space(\"Latent Space after training all\")\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.title(\"Accuracy on SVHN train\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.plot(list(range(1, len(svhn_train_res) + 1)), svhn_train_res)\n",
    "plt.savefig(\"svhn_train_res.png\")\n",
    "\n",
    "plt.title(\"Accuracy on SVHN test\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.plot(list(range(1, len(svhn_test_res) + 1)), svhn_test_res)\n",
    "plt.savefig(\"svhn_test_res.png\")\n",
    "\n",
    "plt.title(\"Accuracy on MNIST test\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.plot(list(range(1, len(mnist_test_res) + 1)), mnist_test_res)\n",
    "plt.savefig(\"mnist_test_res.png\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "SWD Communism.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
